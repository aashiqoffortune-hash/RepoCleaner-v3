#!/usr/bin/env python3
import os
import re
import sys
import argparse
import random
import subprocess
import shutil
from pathlib import Path
import json  # Helps handle JSON files like package.json for clean edits
from datetime import datetime  # For adding timestamps to backups and logs

# List of regex patterns to detect and remove references to "Lovable" (case-insensitive)
# This covers common watermarks, badges, classes, IDs, icons, hooks, and credits
LOVABLE_PATTERNS = [
    r'(?i)(lovable|lovable\.dev|edit with lovable|generated by lovable|don\'t delete this lovable)',
    r'(?i)#lovable-badge',
    r'(?i)class\s*=\s*["\']lovable[^"\']*["\']',
    r'(?i)id\s*=\s*["\']lovable[^"\']*["\']',
    r'(?i)src\s*=\s*["\'][^"\']*lovable[^"\']*\.svg["\']',  # Matches Lovable icon files
    r'(?i)useLovableEdit|lovable-export:\s*true',  # Catches React hooks and export flags
    r'(?i)lovable\.com|powered by lovable',  # Affiliate links and powered-by credits
    r'(?i)"lovable-.*?"',  # Dynamic class or attribute variants
]

# List of neutral replacement strings to optionally insert for natural variation
# These help make changes look like normal refactoring (e.g., generic tool names or comments)
DECOYS = [
    "CustomForge", "DevPhantom", "CodeVoid", "AnonBuilder", "ShadowGen", "UI-Optimizer", "NeutralHub",
    "// Perf-tuned render", "/* Legacy UI hook */", "#app-badge { display: none; }", ".custom-class { opacity: 1; }",
    '"export-tool": "phantom"', '"generator": "void"'  # Safe JSON key replacements
]

def scrub_file(file_path: Path, dry_run: bool = False, mutate: bool = False, verbose: bool = False) -> list[str]:
    """
    Clean a single file by removing Lovable references.
    Supports various file types and optionally adds subtle changes for realism.
    Returns a list of changes made (for logging).
    """
    if not file_path.is_file():
        return []
   
    ext = file_path.suffix.lower()
    # Only process common text-based files to avoid breaking binaries
    if ext not in {'.html', '.js', '.jsx', '.ts', '.tsx', '.css', '.mdx', '.md', '.txt', '.json', '.svg', '.yaml', '.yml', '.toml', '.config'}:
        return []  # Skip unsupported files
   
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except UnicodeDecodeError:
        return []  # Skip if file can't be read as text (e.g., binary)
   
    original_content = content
    changes = []
    match_count = 0
    # Scan for all patterns and count matches
    for pattern in LOVABLE_PATTERNS:
        matches = re.findall(pattern, content, re.MULTILINE | re.IGNORECASE)
        if matches:
            match_count += len(matches)
            # Remove matches: Full blocks for comments/CSS, precise removal otherwise
            if '//' in content or '/*' in content or '#' in content or ext in {'.css', '.svg', '.yaml', '.toml'}:
                content = re.sub(pattern, '', content, flags=re.MULTILINE | re.DOTALL)
            else:
                content = re.sub(pattern, '', content)
   
    if match_count > 0:
        changes.append(f"File {file_path.name}: {match_count} ghosts -> voided")
        if verbose:
            print(f"  - Detailed: Patterns hit in {file_path.name} (pre-purge length: {len(original_content)})")
   
    # Optional mutation: Add random neutral changes to blend edits
    if mutate and random.random() < 0.10:  # About 10% chance per file for subtlety
        decoy = random.choice(DECOYS)
        # For JSON: Recursively scan and replace Lovable-related keys/values
        if ext == '.json':
            try:
                data = json.loads(content)
                def deep_nuke(obj):
                    if isinstance(obj, dict):
                        for k, v in list(obj.items()):
                            if 'lovable' in str(k).lower() or 'lovable' in str(v).lower():
                                obj[k] = decoy if isinstance(v, str) else {"neutral": decoy}
                            else:
                                deep_nuke(v)
                        return obj
                    elif isinstance(obj, list):
                        return [deep_nuke(item) for item in obj]
                    return obj
                data = deep_nuke(data)
                content = json.dumps(data, indent=2)
            except json.JSONDecodeError:
                pass
        else:
            # For other files: Subtly replace up to 3 'lovable' instances with decoys
            for _ in range(min(3, content.lower().count('lovable'))):
                pos = content.lower().find('lovable', random.randint(0, len(content)//2))
                if pos != -1:
                    content = content[:pos] + decoy[:len('lovable')] + content[pos+7:]
   
    # Apply changes if not a dry run
    if changes and not dry_run:
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"‚úì Purged {file_path} ({match_count} evolutions)")
        if verbose:
            print(f"  - Post-purge length: {len(content)} (Delta: {len(original_content) - len(content)} chars)")
   
    return changes

def history_blur(root_path: Path, dry_run: bool, verbose: bool = False):
    """
    Clean Git history logs by replacing Lovable references and slightly altering timestamps.
    This makes the repo look like it was edited naturally over time.
    """
    git_dir = root_path / '.git'
    if git_dir.exists():
        log_files = list(git_dir.glob('logs/refs/heads/*.log')) + [git_dir / 'logs/HEAD']
        blurred_count = 0
        for log_file in log_files:
            if log_file.is_file():
                with open(log_file, 'r') as f:
                    logs = f.readlines()
                mutated = []
                for line in logs:
                    # Replace Lovable refs with decoys
                    mutated.append(re.sub(r'(?i)lovable.*?(?=\s+\d+)', random.choice(DECOYS), line))
                    # Add small timestamp jitter (¬±5 minutes) to avoid exact matches
                    if ' ' in line and ':' in line.split()[-1]:
                        ts_part = line.rsplit(' ', 1)[1]
                        mutated[-1] = line.rsplit(' ', 1)[0] + ' ' + re.sub(r'(\d{2}:\d{2})', lambda m: f"{int(m.group(1)[:2])%24:02d}:{(int(m.group(1)[3:])+random.randint(-5,5))%60:02d}", ts_part)
                if not dry_run:
                    with open(log_file, 'w') as f:
                        f.writelines(mutated)
                    blurred_count += 1
                if verbose:
                    print(f"  - Blurred {log_file.name}: {len(logs)} lines mutated")
        if blurred_count > 0 and verbose:
            print(f"‚úì History abyss: {blurred_count} log veins voided")

def walk_and_scrub(root_path: Path, dry_run: bool, mutate: bool, commit: bool = False, bundle: bool = False, backup: bool = False, verbose: bool = False, new_dir: str = None):
    """
    Main cleaning function: Walks the directory, scrubs files, blurs history,
    handles backups/clones, commits, bundles, and cleans up traces.
    """
    # Optional: Create a timestamped backup ZIP before changes
    if backup:
        backup_name = f"{root_path.name}_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{random.randint(1000,9999)}.zip"
        shutil.make_archive(backup_name, 'zip', root_path)
        print(f"‚úì Backup forged: {backup_name} ‚Äî Original preserved for alibis")
   
    total_changes = []
    # Count total files for progress tracking
    file_count = sum(1 for _ in Path(root_path).rglob('*') if _.is_file())
    processed = 0
    # Walk through all files and clean them
    for dirpath, _, filenames in os.walk(root_path):
        for filename in filenames:
            file_path = Path(dirpath) / filename
            changes = scrub_file(file_path, dry_run, mutate, verbose)
            total_changes.extend(changes)
            processed += 1
            if verbose and processed % 10 == 0:
                print(f"  - Progress: {processed}/{file_count} files clawed")
   
    # Dry run: Just report without changes
    if dry_run:
        print(f"\n--- DRY-RUN v3: {len(total_changes)} evolutions detected across {file_count} files ---")
        for change in total_changes[:20]:  # Show first 20 changes
            print(change)
        if len(total_changes) > 20:
            print("... (truncated for void)")
        return
   
    # Blur Git history after file changes
    history_blur(root_path, dry_run=False, verbose=verbose)
   
    # Optional: Stage, commit, and push changes with a neutral message
    if commit and total_changes:
        try:
            subprocess.run(['git', 'add', '.'], cwd=root_path, check=True, capture_output=True)
            commit_msg = f"perf: ui optimizations and refactor ({random.randint(300,999)})"  # Random number for variety
            subprocess.run(['git', 'commit', '-m', commit_msg], cwd=root_path, check=True, capture_output=True)
            subprocess.run(['git', 'push'], cwd=root_path, check=True, capture_output=True)
            print(f"‚úì Committed eternal: {commit_msg}")
            if verbose:
                print("  - Git delta: Staged all, pushed to origin‚Äîhistory spectral")
        except subprocess.CalledProcessError:
            print("‚ö† Git ritual incomplete‚Äîmanual void advised.")
   
    print(f"\n--- VOID v3 COMPLETE: {len(total_changes)} badges annihilated. Repo: Spectral pure across {file_count} files. ---")
   
    # Optional: Clone cleaned version to a new subdir (keeps original safe)
    if new_dir:
        clone_path = root_path / new_dir
        clone_path.mkdir(exist_ok=True)
        for item in root_path.iterdir():
            if item.is_dir():
                shutil.copytree(item, clone_path / item.name, dirs_exist_ok=True)
            else:
                shutil.copy2(item, clone_path)
        print(f"‚úì Cloned purge to: {new_dir} ‚Äî Original untouched")
        root_path = clone_path  # Use clone for bundling
   
    # Optional: Create a ZIP bundle of the cleaned repo
    if bundle:
        bundle_name = f"{root_path.name}_purged_{random.randint(1000,9999)}.zip"
        shutil.make_archive(bundle_name, 'zip', root_path)
        print(f"‚úì Bundled ghost: {bundle_name} ‚Äî Ready for $4K drops.")
   
    # Clean up temporary files securely (cross-platform)
    temp_files = [__file__, '/tmp/*voidscrub*', f"{root_path.name}_backup_*.zip"] if not backup else [__file__, '/tmp/*voidscrub*']
    for tf in temp_files:
        if '*' in tf:
            for f in Path('.').glob(tf):
                shred_file(f)
        elif os.path.exists(tf):
            shred_file(Path(tf))
   
    # Helper to securely delete files (shred on Unix, cipher on Windows)
    def shred_file(fp: Path):
        try:
            if os.name == 'nt':  # Windows: Use cipher for secure wipe
                subprocess.run(['cipher', '/w:' + str(fp)], shell=True, capture_output=True)
            else:  # Unix: Shred with multiple passes
                os.system(f"shred -u -z -n 7 {fp} 2>/dev/null || true")
            if verbose:
                print(f"  - Shredded trace: {fp.name}")
        except:
            pass

def main():
    """
    Entry point: Parse args and start the cleaning process.
    Defaults to current directory for easy local runs.
    """
    parser = argparse.ArgumentParser(description="VoidScrubber v3: Annihilate Lovable badge evolutions‚ÄîEmpire Scale.")
    parser.add_argument('--path', '-p', type=str, default='.', help='Root dir/repo to purge (default: current)')
    parser.add_argument('--dry-run', '-d', action='store_true', help='Preview evolutions')
    parser.add_argument('--mutate', '-m', action='store_true', help='Inject anti-forensic decoys (default on full run)')
    parser.add_argument('--commit', '-c', action='store_true', help='Auto-git commit/push')
    parser.add_argument('--bundle', '-b', action='store_true', help='ZIP scrubbed repo for drops')
    parser.add_argument('--backup', action='store_true', help='Pre-purge ZIP backup (shred optional)')
    parser.add_argument('--verbose', '-v', action='store_true', help='Detailed change/progress ledger')
    parser.add_argument('--new-dir', '-n', type=str, help='Purge to new subdir clone (original safe)')
    args = parser.parse_args()
   
    root = Path(args.path).resolve()
    if not root.exists():
        sys.exit("‚ùå Void absent‚Äîpath invalid.")
   
    print(f"üî• v3 Initializing on {root} (Lovable ghosts + evos targeted)...")
    walk_and_scrub(root, args.dry_run, args.mutate or not args.dry_run, args.commit, args.bundle, args.backup, args.verbose, args.new_dir)
   
    sys.exit(0)

if __name__ == "__main__":
    main()